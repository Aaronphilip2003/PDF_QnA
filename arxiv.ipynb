{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "def download_pdf_paper_from_url(url):\n",
    "    paper_number = os.path.basename(url).strip(\".pdf\")\n",
    "    res = requests.get(url)\n",
    "    pdf_dir = \"papers\"\n",
    "    os.makedirs(pdf_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "    pdf_path = os.path.join(pdf_dir, f\"{paper_number}.pdf\")\n",
    "    with open(pdf_path, 'wb') as f:\n",
    "        f.write(res.content)\n",
    "    return paper_number\n",
    "\n",
    "link = \"https://arxiv.org/pdf/2306.08302.pdf\"\n",
    "paper_number = download_pdf_paper_from_url(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load using PDFMiner (Langchain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PDFMinerLoader\n",
    "docs    =   PDFMinerLoader(f\"papers/{paper_number}.pdf\").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking with langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter   =   RecursiveCharacterTextSplitter(\n",
    "    chunk_size=700, # Specify the character chunk size\n",
    "    chunk_overlap=0, # \"Allowed\" Overlap across chunks\n",
    "    length_function=len # Function used to evaluate the chunk size (here in terms of characters)\n",
    ")\n",
    "\n",
    "docs    =   text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store vector embeddings using faiss (generated using openAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]  =  \"\"\n",
    "\n",
    "embeddings  =   OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdb_chunks  =  FAISS.from_documents(docs, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdb_chunks.save_local(\"vdb_chunks\", index_name=\"base_and_adjacent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Synergized LLMs + KGs. The synergy of LLMs and KGs\\naims to integrate LLMs and KGs into a unified framework\\n\\nFig. 7. The general framework of the Synergized LLMs + KGs, which\\ncontains four layers: 1) Data, 2) Synergized Model, 3) Technique, and\\n4) Application.\\n\\nfrom KGs, it can significantly improve the performance\\nof LLMs in accessing domain-specific knowledge [94]. To\\nimprove the interpretability of LLMs, researchers also utilize\\nKGs to interpret the facts [14] and the reasoning process of\\nLLMs [95].\\n\\n3.1.2 LLM-augmented KGs', metadata={'source': 'papers/2306.08302.pdf'}),\n",
       " Document(page_content='7.4 Multi-Modal LLMs for KGs', metadata={'source': 'papers/2306.08302.pdf'}),\n",
       " Document(page_content='2) KG-enhanced LLM inference includes research that\\nutilizes KGs during the inference stage of LLMs,\\nwhich enables LLMs to access the latest knowledge\\nwithout retraining.\\n\\n3) KG-enhanced LLM interpretability includes works that\\nuse KGs to understand the knowledge learned by\\nLLMs and interpret the reasoning process of LLMs.\\n\\nLLM-augmented KGs. LLMs can be applied to augment\\nvarious KG-related tasks. We categorize the research on\\nLLM-augmented KGs into five groups based on the task\\ntypes:\\n\\n1)\\n\\n2)\\n\\n3)\\n\\n4)\\n\\n5)', metadata={'source': 'papers/2306.08302.pdf'}),\n",
       " Document(page_content='4.2 KG-enhanced LLM Inference', metadata={'source': 'papers/2306.08302.pdf'})]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vdb_chunks  =   FAISS.load_local(\"vdb_chunks\", embeddings, index_name=\"base_and_adjacent\")\n",
    "vdb_chunks.as_retriever().get_relevant_documents(\"What are KG-enhanced LLMs?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm =   OpenAI(temperature=0.0) # Set temperature to 0.0 as we don't want creative answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "qa  =   RetrievalQAWithSourcesChain.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vdb_chunks.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Give me a brief overview about the paper',\n",
       " 'answer': ' This paper provides an overview of the advanced techniques in both Language Models (LLMs) and Knowledge Graphs (KGs). It covers the state-of-the-art LLMs and novel KGs, and discusses the challenges and future research directions. It was published in the Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), 2019, pp. 2463â€“2473.\\n',\n",
       " 'sources': 'papers/2306.08302.pdf'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa({\"question\" : \"Give me a brief overview about the paper\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
